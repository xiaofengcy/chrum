{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "# INTRODUCTION\n",
    "Challenge-1: Telecom Churn Predictive with Automated Data Science Techniques\n",
    "\n",
    "The goal of this challenge is to perform the telecom churn prediction as defined by the KDD-2009 challenge using supervised learning techniques. This is the second notebook for this challenge and here is a summary of tasks performed in this notebook:\n",
    "\n",
    "1. Retrieve list of columns shortlisted from training data.\n",
    "2. Read test dataset from files, restricting the columns to list from above.\n",
    "3. Read target labels for the test dataset. This will be used for evaluation of predicted results.\n",
    "4. Retrieve auto-sklearn models from disk and predict labels for test dataset.\n",
    "5. Check F1 score and other metrices of the predictions against the evaluation labels.\n",
    "\n",
    "## 1. Column list retrieval\n",
    "Columns shortlisted from training data in notebook-1 is retrieved using pickle.\n",
    "\n",
    "## 2. Parse test data\n",
    "### a. Filter columns.\n",
    "\n",
    "The test data set is parsed using the shortlisted column list from first step.\n",
    "\n",
    "### b. Null values\n",
    "Null values are filled with 0.0 consistent with the approach selected in notebook-1\n",
    "\n",
    "### c. Size reduction\n",
    "Data size reduction can be performed optionally if the test dataframe is hard to run in memory.\n",
    "\n",
    "## 3. Target labels\n",
    "Test labels are retrieved from disk. This will be used to test and validate our predictions.\n",
    "\n",
    "## 4. Model retrieval\n",
    "Retrieve auto-sklearn ensemble model from disk using pickle.\n",
    "\n",
    "Predictions are performed in multiple processes. 5 processes are spawned and each predictcs approximately 1/5rd of the test data separately. The results are then combined into a single prediction array before validating against the test labels.\n",
    "\n",
    "## 5. Check F1 score\n",
    "Check F1 binary scores by validating the predictions against the test labels.\n",
    "\n",
    "<b><u>NOTE</u></b>: Every cell in the notebook is timed (%%time), which gives an idea of the cell runtime.\n",
    "\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## IMPORTED LIBRARIES\n",
    "Here is a summary of the imported modules and their purposes:\n",
    "\n",
    "### Utilities\n",
    "<b>1. pandas</b>\n",
    "<br>To read raw training data from csv files into dtaframes and process it.\n",
    "\n",
    "<b>2. numpy</b>\n",
    "<br>For datatype constants.\n",
    "\n",
    "<b>3. pickle</b>\n",
    "<br>Writing and reading objects to/from disk as binary files. These objects incldue parsed test files, list of columns and trained auto-sklearn model.\n",
    "\n",
    "<b>4. datetime</b>\n",
    "<br>To measure start and end time of the notebook execution. Also used to suffix timestamp to the generated log files.\n",
    "\n",
    "<b>5. os</b>\n",
    "<br>Writing and reading log files and pickles from disk.\n",
    "    \n",
    "### Metrices\n",
    "<b>1. sklearn.metrics.f1_score</b>\n",
    "<br>To evaluate the model using F1 scores of binary classes.\n",
    "\n",
    "<b>2. sklearn.metrics.classification_report</b>\n",
    "<br>To print precision, recall and support\n",
    "\n",
    "### Distributed processing\n",
    "\n",
    "<b>1. multiprocessing</b>\n",
    "<br>For distributing the auto-sklearn prediction workload to multiple CPU cores.\n",
    "\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-16 11:29:19.900616\n"
     ]
    }
   ],
   "source": [
    "#### Utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "#### Metrices\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#### Multi-processing\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## CONSTANTS\n",
    "Specfic details of each constant are indicated in comments below.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.1 ms, sys: 10.9 ms, total: 36 ms\n",
      "Wall time: 35.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#### Constant values\n",
    "\n",
    "#### Data location on the disk - absolute path of unzipped datafiles\n",
    "data_dir           = \"../unzipped_datafiles/\"\n",
    "\n",
    "#### File prefix for training and label files\n",
    "data_file_prefix   = \"orange_large_train.data.chunk\"\n",
    "target_file        = \"orange_large_train_churn.labels\"\n",
    "\n",
    "#### File and columns counts\n",
    "num_files        = 5\n",
    "targ_records     = 25000 ## Num of rows to skip in target file = Num of records to retrieve from target file\n",
    "\n",
    "#### Test dataframes\n",
    "X_test = pd.DataFrame()\n",
    "y_test = pd.Series()\n",
    "\n",
    "#### Log files file prefixes / suffixes\n",
    "time_suffix = str(start)\n",
    "feat_extract_txt   = \"notebook_2_final_\"\n",
    "for ch in [\" \", \":\", \"-\"]:\n",
    "    time_suffix = time_suffix.replace(ch, \"\")\n",
    "\n",
    "f_name_prefix = feat_extract_txt\n",
    "f_name_suffix = \"_\" + time_suffix + \".txt\"\n",
    "temp_log_str  = \"temp_log_\"\n",
    "f_res_name = f_name_prefix + f_name_suffix\n",
    "\n",
    "#### Pickle constants for files that are stored to disk.\n",
    "pkl_cols_to_retain  = \"../pickles/cols_to_retain.pkl\"\n",
    "pkl_automl_model    = \"../pickles/automl_model.pkl.0\"\n",
    "pkl_x_test          = \"../pickles/X_test.pkl\"\n",
    "\n",
    "#### Batch size for multiprocessing. Depends on the number of test data splits that can be handled.\n",
    "batch_size = 5\n",
    "\n",
    "#### Set this to TRUE for faster execution by using the pickled test data from disk. \n",
    "#### If set to FALSE, extraction of test data can take ~4mins.\n",
    "use_saved_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Function: CHECK_AND_UPDATE_DTYPE\n",
    "Helper function that checks the maximum and minimum values of a feature and assigns an appropriate datatype.\n",
    "\n",
    "By default, pandas assigns the highest datatype for a numeric column such as int64 and float64 and this bloats up the dataframe size in memory. Using smaller datatypes, drastically reduces the memory footprint of the dataframes.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 12.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def check_and_update_dtype(dt, mn, mx):\n",
    "    \n",
    "    if (dt == np.int64):\n",
    "        if ((mn >= np.iinfo(\"int8\").min) and (mx < np.iinfo(\"int8\").max)): ##int8\n",
    "            return np.int8\n",
    "        elif ((mn >= np.iinfo(\"int16\").min) and (mx < np.iinfo(\"int16\").max)): ##int16\n",
    "            return np.int16\n",
    "        elif ((mn >= np.iinfo(\"int32\").min) and (mx < np.iinfo(\"int32\").max)): ##int32\n",
    "            return np.int32\n",
    "    elif (dt == np.float64):\n",
    "        if ((mn >= np.finfo(\"float32\").min) and (mx < np.finfo(\"float32\").max)): ##float32\n",
    "            return np.float32\n",
    "    else:\n",
    "        return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Function: REDUCE_DATAFRAME_SIZE\n",
    "Helper function to reduce dataframe size in memory by assigning the right datatype to a feature.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47 µs, sys: 0 ns, total: 47 µs\n",
      "Wall time: 51.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def reduce_dataframe_size(df):\n",
    "    \n",
    "    print(\"Original DF size = \", df.memory_usage(deep=True).sum()/1024**3, \"GB\")\n",
    "    print(\"Reducing DF size....\")\n",
    "    red_df = pd.DataFrame()\n",
    "    for col in df.columns:\n",
    "        dt = df[col].dtype\n",
    "        mn = df[col].min()\n",
    "        mx = df[col].max()\n",
    "        up_dt = check_and_update_dtype(dt, mn, mx)\n",
    "        \n",
    "        red_df = red_df.join(pd.DataFrame(df[col], \n",
    "                                          columns=[col],\n",
    "                                          dtype=up_dt), \n",
    "                             how=\"right\")\n",
    "    print(\"Reduced DF size = \", red_df.memory_usage(deep=True).sum()/1024**3, \"GB\")\n",
    "    return (red_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Function: EXTRACT_TEST_DATA\n",
    "Extracts the last 25k rows from training data and appends that to a dataframe. We treat this dataframe as the test/validation dataset. During parsing we, use the column list retrieved from training in notebook-1.\n",
    "\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 0 ns, total: 12 µs\n",
      "Wall time: 15.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def extract_test_data (num_files=num_files):\n",
    "    \n",
    "    X_test  = pd.DataFrame() \n",
    "\n",
    "    #### Cycle through columns in batches, reduce their dtype and then append to final dataframe.\n",
    "    for i in range(1, num_files+1):\n",
    "\n",
    "        if (i < 3):\n",
    "            continue\n",
    "\n",
    "        chunk_df = pd.DataFrame()\n",
    "        \n",
    "        chunk_df = pd.read_csv(data_dir+data_file_prefix+str(i), \n",
    "                               sep=\"\\t\", \n",
    "                               lineterminator=\"\\n\", \n",
    "                               header=None,\n",
    "                               names=col_list,\n",
    "                               usecols=col_ind)\n",
    "                               #dtype=col_dict)\n",
    "\n",
    "        chunk_df.fillna(0, inplace=True)\n",
    "\n",
    "        if (i == 3):\n",
    "            X_test  = X_test.append(chunk_df.iloc[5001:], ignore_index=True) \n",
    "        else:\n",
    "            X_test  = X_test.append(chunk_df, ignore_index=True)\n",
    "            \n",
    "    del chunk_df\n",
    "    \n",
    "    X_test = reduce_dataframe_size(X_test)\n",
    "        \n",
    "    return (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Function: PRINT_ENSEMBLE_DETAILS\n",
    "Helper function that prints the details of the selected model, such as the hyperparameters, weights etc.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 µs, sys: 0 ns, total: 21 µs\n",
      "Wall time: 25.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#### Get raw details of selected ensemble. Each algo+hyperparamter combination is stored as a dictionary\n",
    "def print_ensemble_details (mod_with_wt):\n",
    "\n",
    "    #### Build list of the ensemble detail dictionary\n",
    "    dict_list = []\n",
    "    for item in mod_with_wt:\n",
    "        co_dict   = {}\n",
    "        pip = item[1]\n",
    "        co_dict = pip.configuration.get_dictionary().copy()\n",
    "        co_dict[\"algo_weight\"] = item[0]\n",
    "        dict_list.append(co_dict)\n",
    "\n",
    "    #### Build a dictionary with the key is the hyperparamter name and value is a list corresponding to the hyperparamter\n",
    "    #### values of the ensemble in that order.\n",
    "    print_dict = {}\n",
    "    for item in dict_list:\n",
    "        for key, val in item.items():\n",
    "            if key in print_dict.keys():\n",
    "                pass\n",
    "            else:\n",
    "                print_dict[key] = []\n",
    "\n",
    "    for item in dict_list:\n",
    "        for key in print_dict.keys():\n",
    "            if key in item.keys():\n",
    "                print_dict[key].append(item[key])\n",
    "            else:\n",
    "                print_dict[key].append(\"NA\")\n",
    "\n",
    "    #### Read the dictionary into a pandas dataframe which is easier to print as a table in the end.\n",
    "    print_df = pd.DataFrame(print_dict)\n",
    "    col_dict = {}\n",
    "    drop_list  = []\n",
    "    const_dict = {}\n",
    "\n",
    "    for col in print_df.columns:\n",
    "\n",
    "        #### Remove parameters that are not relevant. For e.g. \n",
    "        #### 1. There are no categorical columns in our dataset\n",
    "        #### 2. There is no preprocessing / imputation done becasue the null values are filled before training the automl.\n",
    "        if ((\"categorical\" in col) or (\"preprocessor\" in col) or (\"imputation\" in col)) :\n",
    "            drop_list.append(col)\n",
    "        else:\n",
    "            str1 = col.split(\":\")\n",
    "\n",
    "            if (len(str1) > 2):\n",
    "                title = str1[2]\n",
    "            else:\n",
    "                title = str1[0]\n",
    "\n",
    "            #### Seprate parameters that have constant values for the ensemble.\n",
    "            if (len(print_df[col].unique()) == 1):\n",
    "                val = print_df[col].unique()[0]\n",
    "                if (val == \"None\" or val == 0):\n",
    "                    pass\n",
    "                else:\n",
    "                    const_dict[title] = val\n",
    "                drop_list.append(col)\n",
    "            else:\n",
    "                col_dict[col] = title\n",
    "\n",
    "    print_df = print_df.drop(drop_list, axis=1)\n",
    "    print_df = print_df.rename(col_dict, axis=1)\n",
    "\n",
    "    print(\"ENSEMBLE Constants\")\n",
    "    print(\"------------------\")\n",
    "    for k, v in const_dict.items():\n",
    "        print (k, \"\\t= \", v)\n",
    "\n",
    "    print(\"\\n\\nENSEMBLE Hyperparameters\")\n",
    "    print(\"------------------------\")\n",
    "\n",
    "    #print_df = print_df[[\"algo_weight\", \n",
    "    #                     \"max_features\", \n",
    "    #                     \"rescaling\", \n",
    "    #                     \"n_quantiles\", \n",
    "    #                     \"output_distribution\",\n",
    "    #                     \"bootstrap\",\n",
    "    #                     \"criterion\", \n",
    "    #                     \"min_samples_leaf\", \n",
    "    #                     \"min_samples_split\"]]\n",
    "\n",
    "    print_df.index = np.arange(1, len(print_df)+1)\n",
    "    \n",
    "    return print_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Function: SPAWN_PRED_PROCESS\n",
    "Function that spawns a worker process for auto-sklearn prediction. The predictions are then put to the queue associated with this process.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def spawn_pred_process(automl_model, test_data, queue, identity):\n",
    "    #print(automl_model)\n",
    "    print(\"Worker process-%d initiated....\\n\" %identity)\n",
    "    pred = automl_model.predict(test_data)\n",
    "    queue.put(pred)\n",
    "    print(\"Worker process-%d completed....\\n\" %identity)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Column List\n",
    "Retrieve column list shortlisted from pre-processing and training in notebook-1. This list will be used to retrieve reduced columns from the test set.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of columns to filter:\n",
      "Index(['Var7', 'Var11', 'Var13', 'Var17', 'Var19', 'Var20', 'Var21', 'Var22',\n",
      "       'Var27', 'Var28',\n",
      "       ...\n",
      "       'Var14696', 'Var14703', 'Var14710', 'Var14713', 'Var14714', 'Var14721',\n",
      "       'Var14724', 'Var14729', 'Var14731', 'Var14732'],\n",
      "      dtype='object', length=2907) \n",
      "\n",
      "Total Columns:  2907\n",
      "CPU times: user 6.86 ms, sys: 0 ns, total: 6.86 ms\n",
      "Wall time: 5.87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#### Shortlisted columns and their types\n",
    "col_list = pickle.load(file=open(pkl_cols_to_retain, \"rb\"))\n",
    "col_ind  = [int(num.replace(\"Var\", \"\"))-1 for num in col_list]\n",
    "\n",
    "print(\"List of columns to filter:\")\n",
    "print(col_list, \"\\n\")\n",
    "print(\"Total Columns: \", len(col_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Extract Test Data\n",
    "Extract the 25k rows of test data.\n",
    "\n",
    "The original size of the dataframe is ~550MB. However we can optimize this by reducing the datatypes of the features just like it was done during training in notebook-1. \n",
    "\n",
    "For datasize reduction we utilize another approach of reducing the datatype. This is done by cycling through the columns, reducing the datatype and then appending this column to a new dataframe. We observed this is much faster than using .astype() function of pandas because .astype() takes about 6secs per feature. With this approach, it takes less than a half second per feature. However, with ~3k features, this needs ~4mins. The final dataframe size is ~121MB.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint of X_test:  0.16072306782007217 GB\n",
      "Shape of X_test:  (25000, 2907)\n",
      "CPU times: user 346 ms, sys: 134 ms, total: 480 ms\n",
      "Wall time: 481 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#### To speed up execution of this cell, set use_saved_data boolean accordingly in CONSTANTS \n",
    "#### cell at the start of the notebook.\n",
    "\n",
    "if use_saved_data == False:\n",
    "    X_test = extract_test_data()\n",
    "\n",
    "    #### Store the text dataframe to disk\n",
    "    pickle.dump(file=open(pkl_x_test, \"wb\"), obj=X_test)\n",
    "else:\n",
    "    #### Load picked data from disk\n",
    "    X_test = pickle.load(file=open(pkl_x_test, \"rb\"))\n",
    "\n",
    "print (\"Memory footprint of X_test: \", X_test.memory_usage(deep=True).sum()/1024**3, \"GB\")\n",
    "print (\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Predict\n",
    "We now fork as many processes as there are automl models (which again depends on the training batches of notebook-1). \n",
    "\n",
    "Every process is associated with a queue where the process writes its predicted values.\n",
    "\n",
    "Appending the queue objects to a list in order and then extracting them in the same order, ensures that we combining the results of split test batches as in the original test set, even though worker processes may get completed asynchronously.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of split batch:  (5000, 2907)\n",
      "Worker process-0 initiated....\n",
      "\n",
      "Shape of split batch:  (5000, 2907)\n",
      "Worker process-1 initiated....\n",
      "\n",
      "Shape of split batch:  (5000, 2907)\n",
      "Worker process-2 initiated....\n",
      "\n",
      "Shape of split batch:  (5000, 2907)\n",
      "Worker process-3 initiated....\n",
      "\n",
      "Shape of split batch:  (5000, 2907)\n",
      "Worker process-4 initiated....\n",
      "\n",
      "Worker process-0 completed....\n",
      "\n",
      "Worker process-1 completed....\n",
      "\n",
      "Worker process-2 completed....\n",
      "\n",
      "Worker process-3 completed....\n",
      "\n",
      "Worker process-4 completed....\n",
      "\n",
      "CPU times: user 14 s, sys: 4.35 s, total: 18.3 s\n",
      "Wall time: 49.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    predictions   = []\n",
    "    processes     = []\n",
    "    queues        = []\n",
    "    ind = 0\n",
    "    count = 0\n",
    "    \n",
    "    with open(pkl_automl_model, \"rb\") as fp:\n",
    "        model = pickle.load(file=fp)\n",
    "\n",
    "    while (ind < len(X_test)):\n",
    "        \n",
    "        end = ind + int(len(X_test)/batch_size)\n",
    "        X_test_split = X_test.iloc[ind:end, ].copy()\n",
    "        ind = end\n",
    "        print(\"Shape of split batch: \", X_test_split.shape)\n",
    "\n",
    "        q = Queue()\n",
    "        p = Process(target=spawn_pred_process, args=(model, X_test_split, q, count))\n",
    "        p.start()\n",
    "        queues.append(q)\n",
    "        processes.append(p)\n",
    "        count += 1\n",
    "\n",
    "    for proc, que in zip(processes, queues):\n",
    "        predictions.append(que.get())\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Model Ensemble Description\n",
    "Auto-sklearn builds an ensemble of models that best classify the dataset. We have restricted the classifier selection to RandomForest, since this seems to provide the best results until now. Auto-sklearn then builds an ensemble of RandomForest Classifier models with varying hyperparameter values. In our approach we had divided the training set into batches to reduce the number of majority samples in each batch. Subsequently, each batch was trained separately in auto-sklearn producing different set of model ensembles. These sets are shown below along with their selected hyper parameters that provided the best scoring value, which in our case is ROC_AUC. \n",
    "\n",
    "For example, ensemble-1 below, contains 17 RandomForest Classifier models and here is a brief description of the columns:\n",
    "\n",
    "1. <b>balancing</b>\n",
    "This describes if the samples are weighted in the model.\n",
    "\n",
    "2. <b>rescaling</b>\n",
    "This describes how the feature values were scaled.\n",
    "\n",
    "3. <b>bootstrap</b>\n",
    "This describes if the boostrapping based resampling was performed during training. Basically this means that a sample of dataset is used from the training dataset for each training iteration and its possible that a sample appears multiple times in different iterations.\n",
    "\n",
    "4. <b>criterion</b>\n",
    "In tree based classification, there are two criteria used for spltting at a node - <b>gini</b> that reduces the probability of mis-classification at a node and <b>entropy</b> that reduces the impurity of classification at a node.\n",
    "\n",
    "5. <b>max_features</b>\n",
    "It seems auto-sklearn applies it's own feature dimensionality reduction techniques. Hence every model seems to be using anly a fraction of the total available features.\n",
    "\n",
    "6. <b>min_samples_leaf</b>\n",
    "Minimum no: of samples at a leaf node of the tree.\n",
    "\n",
    "7. <b>min_samples_split</b>\n",
    "Minimum no: of samples at a node, before it is split into branches.\n",
    "\n",
    "8. <b>algo_weight</b>\n",
    "This describes the weight of the predictions that the model contributes to the ensemble. For instance 0.16 indciates that 16% of the perdiction weight comes from this model. In the first ensemble there is a very good distribution of weights across the ensemble, while in the second ensemble 46% of the prediction wieght is provided by the first model.\n",
    "\n",
    "9. <b>q_max, q_min, n_quantiles and output_distrubtion</b>\n",
    "This describes the values based on selected scaling methods.\n",
    "\n",
    "It should also be noted that each ensemble is different. For example in the second ensemble, mdoels are primarily driven by rescaling techniques other than normal standardizer while criterion and boostrapping has been kept constant. This kind of shows how the different samples in the same dataset can produce different ensemble strategies.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "*****MODEL-ENSEMBLE*****\n",
      "========================\n",
      "ENSEMBLE Constants\n",
      "------------------\n",
      "classifier \t=  random_forest\n",
      "n_estimators \t=  100\n",
      "\n",
      "\n",
      "ENSEMBLE Hyperparameters\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balancing</th>\n",
       "      <th>rescaling</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>algo_weight</th>\n",
       "      <th>n_quantiles</th>\n",
       "      <th>output_distribution</th>\n",
       "      <th>q_max</th>\n",
       "      <th>q_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>standardize</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.844016</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighting</td>\n",
       "      <td>none</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.881737</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighting</td>\n",
       "      <td>quantile_transformer</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.849415</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>116</td>\n",
       "      <td>normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighting</td>\n",
       "      <td>none</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.833178</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighting</td>\n",
       "      <td>none</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.901453</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighting</td>\n",
       "      <td>quantile_transformer</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.970101</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>130</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weighting</td>\n",
       "      <td>none</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.901453</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weighting</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.907332</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.92252</td>\n",
       "      <td>0.286795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weighting</td>\n",
       "      <td>none</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.975166</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighting</td>\n",
       "      <td>quantile_transformer</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.971916</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>157</td>\n",
       "      <td>normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>weighting</td>\n",
       "      <td>quantile_transformer</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.970101</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0.02</td>\n",
       "      <td>644</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>weighting</td>\n",
       "      <td>quantile_transformer</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.970101</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>905</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>weighting</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.907332</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.830663</td>\n",
       "      <td>0.25349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>weighting</td>\n",
       "      <td>minmax</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.970989</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>weighting</td>\n",
       "      <td>minmax</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.970989</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>weighting</td>\n",
       "      <td>minmax</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.970989</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>weighting</td>\n",
       "      <td>robust_scaler</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.907332</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.92252</td>\n",
       "      <td>0.286795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>weighting</td>\n",
       "      <td>standardize</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.912047</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>weighting</td>\n",
       "      <td>quantile_transformer</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.849415</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>116</td>\n",
       "      <td>normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    balancing             rescaling bootstrap criterion  max_features  \\\n",
       "1        none           standardize     False   entropy      0.844016   \n",
       "2   weighting                  none      True   entropy      0.881737   \n",
       "3   weighting  quantile_transformer      True   entropy      0.849415   \n",
       "4   weighting                  none      True   entropy      0.833178   \n",
       "5   weighting                  none      True      gini      0.901453   \n",
       "6   weighting  quantile_transformer      True   entropy      0.970101   \n",
       "7   weighting                  none      True      gini      0.901453   \n",
       "8   weighting         robust_scaler      True   entropy      0.907332   \n",
       "9   weighting                  none      True   entropy      0.975166   \n",
       "10  weighting  quantile_transformer      True      gini      0.971916   \n",
       "11  weighting  quantile_transformer      True   entropy      0.970101   \n",
       "12  weighting  quantile_transformer      True   entropy      0.970101   \n",
       "13  weighting         robust_scaler      True   entropy      0.907332   \n",
       "14  weighting                minmax      True   entropy      0.970989   \n",
       "15  weighting                minmax      True   entropy      0.970989   \n",
       "16  weighting                minmax      True   entropy      0.970989   \n",
       "17  weighting         robust_scaler      True   entropy      0.907332   \n",
       "18  weighting           standardize      True   entropy      0.912047   \n",
       "19  weighting  quantile_transformer      True   entropy      0.849415   \n",
       "\n",
       "    min_samples_leaf  min_samples_split  algo_weight n_quantiles  \\\n",
       "1                 20                 18         0.18          NA   \n",
       "2                  7                  9         0.14          NA   \n",
       "3                 10                  3         0.12         116   \n",
       "4                 15                 13         0.10          NA   \n",
       "5                 19                  3         0.06          NA   \n",
       "6                 17                  9         0.06         130   \n",
       "7                 19                  3         0.04          NA   \n",
       "8                 19                  2         0.04          NA   \n",
       "9                 15                 19         0.04          NA   \n",
       "10                17                 11         0.04         157   \n",
       "11                17                  6         0.02         644   \n",
       "12                17                  5         0.02         905   \n",
       "13                19                  2         0.02          NA   \n",
       "14                17                  9         0.02          NA   \n",
       "15                17                 13         0.02          NA   \n",
       "16                17                 16         0.02          NA   \n",
       "17                20                  2         0.02          NA   \n",
       "18                19                 20         0.02          NA   \n",
       "19                10                  3         0.02         116   \n",
       "\n",
       "   output_distribution     q_max     q_min  \n",
       "1                   NA        NA        NA  \n",
       "2                   NA        NA        NA  \n",
       "3               normal        NA        NA  \n",
       "4                   NA        NA        NA  \n",
       "5                   NA        NA        NA  \n",
       "6              uniform        NA        NA  \n",
       "7                   NA        NA        NA  \n",
       "8                   NA   0.92252  0.286795  \n",
       "9                   NA        NA        NA  \n",
       "10              normal        NA        NA  \n",
       "11             uniform        NA        NA  \n",
       "12             uniform        NA        NA  \n",
       "13                  NA  0.830663   0.25349  \n",
       "14                  NA        NA        NA  \n",
       "15                  NA        NA        NA  \n",
       "16                  NA        NA        NA  \n",
       "17                  NA   0.92252  0.286795  \n",
       "18                  NA        NA        NA  \n",
       "19              normal        NA        NA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 5.08 s, sys: 2.21 s, total: 7.3 s\n",
      "Wall time: 7.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#### Print model ensemble details\n",
    "with open(pkl_automl_model, \"rb\") as fp:\n",
    "    model = pickle.load(file=fp)\n",
    "\n",
    "    print(\"========================\")\n",
    "    print(\"*****MODEL-ENSEMBLE*****\")\n",
    "    print(\"========================\")\n",
    "\n",
    "    display(print_ensemble_details(model.get_models_with_weights()))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Combine results from models\n",
    "We combine up the results from models (to make one single array). \n",
    "\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from all batches:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-1, -1, -1, ..., -1, -1, -1]),\n",
       " array([-1, -1, -1, ...,  1, -1, -1]),\n",
       " array([-1, -1, -1, ...,  1, -1, -1]),\n",
       " array([-1, -1, -1, ..., -1, -1, -1]),\n",
       " array([-1, -1, -1, ..., -1, -1, -1])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined final prediction:\n",
      "[-1 -1 -1 ... -1 -1 -1]\n",
      "CPU times: user 5.04 ms, sys: 0 ns, total: 5.04 ms\n",
      "Wall time: 3.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Predictions from all batches:\")\n",
    "display(predictions)\n",
    "\n",
    "y_pred = np.concatenate(predictions, axis=0)\n",
    "\n",
    "print(\"Combined final prediction:\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "## Parse test labels\n",
    "We now read the test labels from disk. This will be used for validating our predictions.\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint of y_test:  0.00018633902072906494 GB\n",
      "Shape of y_test:  (25000,)\n",
      "CPU times: user 11.3 ms, sys: 1.05 ms, total: 12.3 ms\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#### Get labels for test data to check accuracy\n",
    "y_test = pd.read_csv(data_dir+target_file, header=None, squeeze=True, skiprows=targ_records)\n",
    "\n",
    "print (\"Memory footprint of y_test: \", y_test.memory_usage(deep=True)/1024**3, \"GB\")\n",
    "print (\"Shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: black; font-family: 'courier new'; font-size: 1.2em\">\n",
    "\n",
    "# Scores\n",
    "Finally the precision, recall and f1 scores are displayed for the model predictions.\n",
    "\n",
    "## F1 Score\n",
    "No Churn  (-1): \t <b>0.9177</b>\n",
    "<br>Churn (+1): \t <b>0.245</b>\n",
    "<b>--------------------------------------------------------------------------------------------------</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Binary Score:\n",
      "---------------\n",
      "No Churn (-1): \t 0.9177\n",
      "Churn    (+1): \t 0.245\n",
      "\n",
      "\n",
      "Classification report:\n",
      "---------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Churn (-1)       0.94      0.89      0.92     23173\n",
      "   Churn (+1)       0.19      0.33      0.24      1827\n",
      "\n",
      "    micro avg       0.85      0.85      0.85     25000\n",
      "    macro avg       0.57      0.61      0.58     25000\n",
      " weighted avg       0.89      0.85      0.87     25000\n",
      "\n",
      "CPU times: user 27.7 ms, sys: 1.91 ms, total: 29.6 ms\n",
      "Wall time: 28.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open (f_res_name, \"a\") as ar:\n",
    "\n",
    "    ar.write (\"------------------Scores----------------------------\\n\\n\")\n",
    "    \n",
    "    #### Default / Binary Scores\n",
    "    class_rep = classification_report(y_pred=y_pred, y_true=y_test, labels=[-1, +1], \n",
    "                                      target_names=[\"No Churn (-1)\", \"Churn (+1)\"])\n",
    "\n",
    "    f1_scor = f1_score(y_true=y_test, y_pred=y_pred, average=None)\n",
    "\n",
    "    print (\"\\nF1 Binary Score:\")\n",
    "    print (\"---------------\")\n",
    "    print (\"No Churn (-1): \\t\", np.round(f1_scor[0], 4))\n",
    "    print (\"Churn    (+1): \\t\", np.round(f1_scor[1], 4))\n",
    "    print(\"\\n\")\n",
    "    ar.write (\"\\n\\n\" + str(f1_score))  \n",
    "    \n",
    "    print (\"Classification report:\")\n",
    "    print (\"---------------------\")\n",
    "    print (class_rep)\n",
    "    ar.write (\"\\n\\n\" + str(class_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-16 11:31:53.418358\n",
      "0:02:33.517742\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "print(end)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
